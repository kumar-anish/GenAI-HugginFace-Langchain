{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face x LangChain : A new partner package in LangChain\n",
    "langchain_huggingface, a partner package in LangChain jointly maintained by Hugging Face and LangChain. This new Python package is designed to bring the power of the latest development of Hugging Face into LangChain and keep it up to date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_huggingface in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (0.0.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from langchain_huggingface) (0.24.6)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.52 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from langchain_huggingface) (0.2.33)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from langchain_huggingface) (2.6.0)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from langchain_huggingface) (0.19.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from langchain_huggingface) (4.44.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.11.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (0.1.99)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (8.5.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.14.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (10.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from transformers>=4.39.0->langchain_huggingface) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain_huggingface) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_huggingface) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_huggingface) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2024.7.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->langchain_huggingface) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2021.13.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (0.24.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from huggingface_hub) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from huggingface_hub) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from huggingface_hub) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from requests->huggingface_hub) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ka\\ai-projects\\langchain\\venvllm\\lib\\site-packages (from requests->huggingface_hub) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "## API Call\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFaceEndpoint\n",
    "#### How to Access HuggingFace Models with API\n",
    "There are also two ways to use this class. You can specify the model with the repo_id parameter. Those endpoints use the serverless API, which is particularly beneficial to people using pro accounts or enterprise hub. Still, regular users can already have access to a fair amount of request by connecting with their HF token in the environment where they are executing the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "c:\\Users\\ka\\AI-Projects\\LangChain\\venvllm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', temperature=0.7, model_kwargs={'max_length': 150, 'token': ''}, model='mistralai/Mistral-7B-Instruct-v0.3', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=150,temperature=0.7,token=os.getenv(\"HF_TOKEN\"))\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?\\n\\nMachine learning is a type of artificial intelligence (AI) that allows software applications to become more accurate in predicting outcomes without being explicitly programmed to do so. It works by analyzing and learning patterns in data, and using that information to make decisions or predictions about new data.\\n\\nThere are several types of machine learning, including supervised learning, unsupervised learning, and reinforcement learning. Supervised learning involves training a model on labeled data, where the correct output is provided for each input. Unsupervised learning involves training a model on unlabeled data, where the model must find patterns and structure on its own. Reinforcement learning involves training a model to make decisions in an environment where it receives feedback in the form of rewards or punishments.\\n\\nMachine learning is used in a wide range of applications, including image and speech recognition, natural language processing, and predictive analytics. It is a powerful tool that can help businesses make more informed decisions, improve efficiency, and provide better customer experiences. However, it also raises important ethical and privacy concerns, as machine learning systems can sometimes make decisions that are biased, opaque, or harmful.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"🎨?\\n\\nGenerative AI is a subset of artificial intelligence that uses algorithms to create new content, such as images, music, or text, based on the patterns it has learned from existing data. It works by analyzing large amounts of data and using statistical models to generate new content that is similar to the original data but also has unique and creative elements. Generative AI can be used in a variety of applications, such as art, design, music, and writing, to automate the creation of new content or to inspire human creators. Examples of generative AI include DeepDream, DALL-E, and DeepMind's AlphaGo.\\n\\nHow does generative AI work?\\n\\nGenerative AI works by using algorithms to create new content based on the patterns it has learned from existing data. There are several types of generative AI models, including Markov chains, recurrent neural networks (RNNs), and generative adversarial networks (GANs).\\n\\nMarkov chains are a type of probabilistic model that can be used to generate sequences of data based on the probability of one data point being followed by another. For example, a Markov chain can be used to generate a sequence of letters that resembles a sentence in English by looking at the probability of one letter being followed by another.\\n\\nRNNs are a type of neural network that can process sequential data, such as a sequence of words in a sentence. They are trained on a large dataset of sequential data, such as a corpus of text, and use the learned patterns to generate new sequences of data.\\n\\nGANs are a type of neural network that consists of two parts: a generator and a discriminator. The generator is responsible for creating new content, such as an image, and the discriminator is responsible for determining whether the generated content is real or fake. The generator and discriminator are trained together, with the generator trying to fool the discriminator and the discriminator trying to accurately classify the generated content as real or fake. Over time, the generator learns to create more realistic and convincing content.\\n\\nGenerative AI is trained on large amounts of data, such as a dataset of images or a corpus of text. The data is used to learn the patterns and statistical relationships between the different elements of the data, such as the relationships between the pixels in an image or the relationships between the words in a sentence. Once the\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is generative AI \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', temperature=0.7, model_kwargs={'max_length': 150, 'token': ''}, model='mistralai/Mistral-7B-Instruct-v0.3', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=150,temperature=0.7,token=os.getenv(\"HF_TOKEN\"))\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?\\n\\nMachine learning is a type of artificial intelligence (AI) that allows software applications to become more accurate in predicting outcomes without being explicitly programmed to do so. It works by analyzing and learning patterns in data, and using that information to make decisions or predictions about new data.\\n\\nThere are several types of machine learning, including supervised learning, unsupervised learning, and reinforcement learning. Supervised learning involves training a model on labeled data, where the correct output is provided for each input. Unsupervised learning involves training a model on unlabeled data, where the model must find patterns and structure on its own. Reinforcement learning involves training a model to make decisions in an environment where it receives feedback in the form of rewards or punishments.\\n\\nMachine learning is used in a wide range of applications, including image and speech recognition, natural language processing, and predictive analytics. It is a powerful tool that can help businesses make more informed decisions, improve efficiency, and provide better customer experiences. However, it also raises important ethical and privacy concerns, as machine learning systems can sometimes make decisions that are biased, opaque, or harmful.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', temperature=0.7, model_kwargs={'max_length': 150, 'token': ''}, model='mistralai/Mistral-7B-Instruct-v0.3', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=150,temperature=0.7,token=os.getenv(\"HF_TOKEN\"))\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] template='\\nQuestion:{question}\\nAnswer:Lets think step by step.\\n'\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate,LLMChain\n",
    "template=\"\"\"\n",
    "Question:{question}\n",
    "Answer:Lets think step by step.\n",
    "\"\"\"\n",
    "prompt=PromptTemplate(template=template,input_variables=[\"question\"])\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?\\n\\nIndia won the cricket World Cup 2011.\\n\\nIndia defeated Sri Lanka in the final match of the World Cup, held on April 2, 2011, at the Wankhede Stadium, Mumbai, India. The final score was 277/4 (50 overs) for India and 274/6 (50 overs) for Sri Lanka, making it a 6-wicket win for India.\\n\\nYuvraj Singh was declared the Man of the Series for his outstanding performance in the tournament, including scoring 362 runs and taking 15 wickets. The Man of the Match in the final match was Gautam Gambhir, who scored 97 runs.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain=LLMChain(llm=llm,prompt=prompt)\n",
    "llm.invoke(\"Who won the cricket World cup 2011\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = hf.embed_query(\"hi this is harrison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.02841656282544136,\n",
       " 0.012183274142444134,\n",
       " 0.027443937957286835,\n",
       " -0.054828692227602005,\n",
       " 0.024238891899585724,\n",
       " 0.0007662787102162838,\n",
       " 0.06783363968133926,\n",
       " 0.016348332166671753,\n",
       " -0.018950749188661575,\n",
       " 0.01254290621727705,\n",
       " 0.021564997732639313,\n",
       " -0.08793036639690399,\n",
       " 0.0006460570730268955,\n",
       " 0.03327079117298126,\n",
       " 0.00546374823898077,\n",
       " -0.060376446694135666,\n",
       " 0.05042263865470886,\n",
       " 0.004434819798916578,\n",
       " 0.0009598685428500175,\n",
       " 0.0017405637772753835,\n",
       " 0.003298850730061531,\n",
       " 0.03167249634861946,\n",
       " -0.04880746454000473,\n",
       " -0.04481915384531021,\n",
       " 0.07132107764482498,\n",
       " -0.007510880008339882,\n",
       " -0.0011259402381256223,\n",
       " -0.01580115407705307,\n",
       " -0.029402373358607292,\n",
       " -0.17224563658237457,\n",
       " -0.03189520165324211,\n",
       " -0.001629141392186284,\n",
       " 0.018104970455169678,\n",
       " 0.015315398573875427,\n",
       " -0.020729582756757736,\n",
       " -0.00887297559529543,\n",
       " -0.001282255630940199,\n",
       " 0.02727689780294895,\n",
       " -0.010114246979355812,\n",
       " 0.012621607631444931,\n",
       " -0.007077880669385195,\n",
       " -0.01669318601489067,\n",
       " 0.04085584357380867,\n",
       " 0.02393835224211216,\n",
       " -0.020081527531147003,\n",
       " 0.028681157156825066,\n",
       " -0.019400738179683685,\n",
       " -0.014618187211453915,\n",
       " 0.017379634082317352,\n",
       " 0.0041641066782176495,\n",
       " 0.06415646523237228,\n",
       " 0.047683075070381165,\n",
       " 0.0018364907009527087,\n",
       " -8.07240794529207e-05,\n",
       " 0.016596786677837372,\n",
       " 0.011124215088784695,\n",
       " 0.06969437003135681,\n",
       " 0.05182049050927162,\n",
       " 0.05568528547883034,\n",
       " 0.055515412241220474,\n",
       " 0.0005039244424551725,\n",
       " 0.04187057539820671,\n",
       " -0.15344087779521942,\n",
       " 0.05180782824754715,\n",
       " 0.006689806934446096,\n",
       " -0.03167073801159859,\n",
       " -0.009105008095502853,\n",
       " -0.05160471796989441,\n",
       " 0.0425085723400116,\n",
       " 0.028200047090649605,\n",
       " -0.010748122818768024,\n",
       " 0.022405777126550674,\n",
       " 0.04439552500844002,\n",
       " 0.004115519113838673,\n",
       " 0.01899847202003002,\n",
       " -0.004357193596661091,\n",
       " 0.04762762039899826,\n",
       " 0.011824612505733967,\n",
       " 0.00816460233181715,\n",
       " 0.008177299052476883,\n",
       " -0.009698739275336266,\n",
       " -0.014260297641158104,\n",
       " 0.011409715749323368,\n",
       " -0.07362115383148193,\n",
       " -0.05439522862434387,\n",
       " -0.057039640843868256,\n",
       " -0.0036085406318306923,\n",
       " 0.002666064305230975,\n",
       " 0.02378249354660511,\n",
       " 0.01537622231990099,\n",
       " -0.07020369172096252,\n",
       " -0.03130035102367401,\n",
       " -0.0031142905354499817,\n",
       " -0.015812166035175323,\n",
       " -0.037913985550403595,\n",
       " -0.02592192403972149,\n",
       " 0.01816839911043644,\n",
       " -0.03882463648915291,\n",
       " -0.05674506723880768,\n",
       " 0.5792059302330017,\n",
       " -0.05278834328055382,\n",
       " 0.020716402679681778,\n",
       " 0.06794388592243195,\n",
       " -0.04541653394699097,\n",
       " 0.01164244394749403,\n",
       " -0.021571768447756767,\n",
       " 0.020341748371720314,\n",
       " -0.027448944747447968,\n",
       " -0.04558894783258438,\n",
       " -0.029443591833114624,\n",
       " -0.023662500083446503,\n",
       " -0.034315284341573715,\n",
       " 0.0019388574874028563,\n",
       " -0.07095137983560562,\n",
       " 0.03455633670091629,\n",
       " -0.03055896796286106,\n",
       " 0.039078615605831146,\n",
       " -0.029707318171858788,\n",
       " -0.0008283121278509498,\n",
       " -0.012159358710050583,\n",
       " -0.01827280782163143,\n",
       " 0.02548651024699211,\n",
       " -0.0044616591185331345,\n",
       " 0.01633531041443348,\n",
       " 0.019126499071717262,\n",
       " -0.05483206361532211,\n",
       " 0.02763599529862404,\n",
       " -0.0047576772049069405,\n",
       " 0.05900171771645546,\n",
       " -0.0016944746021181345,\n",
       " 0.008015012368559837,\n",
       " -0.03772683069109917,\n",
       " -0.09893041849136353,\n",
       " -0.02257438562810421,\n",
       " -0.03760464861989021,\n",
       " -0.0021698628552258015,\n",
       " 0.0032445986289530993,\n",
       " -0.01920253597199917,\n",
       " -0.008631221018731594,\n",
       " -0.048023100942373276,\n",
       " 0.008696702308952808,\n",
       " -0.09516110271215439,\n",
       " -0.03496049344539642,\n",
       " -0.04360798001289368,\n",
       " -0.00034398335264995694,\n",
       " -0.010173679329454899,\n",
       " -0.030999554321169853,\n",
       " 0.02430969849228859,\n",
       " -0.02040201984345913,\n",
       " 0.031139399856328964,\n",
       " 0.0008811268489807844,\n",
       " 0.013916460797190666,\n",
       " -0.031196201220154762,\n",
       " -0.03715403378009796,\n",
       " 0.004029629286378622,\n",
       " 0.014799779281020164,\n",
       " 0.04318894445896149,\n",
       " 0.03875483199954033,\n",
       " 0.013851990923285484,\n",
       " 0.019797883927822113,\n",
       " 0.010267062112689018,\n",
       " -0.0054340967908501625,\n",
       " -0.014299212954938412,\n",
       " 0.027637841179966927,\n",
       " 0.009802662767469883,\n",
       " -0.13550283014774323,\n",
       " -0.017139771953225136,\n",
       " 0.017617117613554,\n",
       " 0.023132259026169777,\n",
       " 0.0017590026836842299,\n",
       " 0.03088942915201187,\n",
       " 0.0399186834692955,\n",
       " -0.013684183359146118,\n",
       " 0.02481652982532978,\n",
       " 0.05405016615986824,\n",
       " 0.017761152237653732,\n",
       " -0.018475065007805824,\n",
       " 0.025955388322472572,\n",
       " -0.006377511657774448,\n",
       " -0.01658732444047928,\n",
       " 0.03784799948334694,\n",
       " -0.02729003317654133,\n",
       " -0.052845802158117294,\n",
       " -0.038033198565244675,\n",
       " 0.05191108211874962,\n",
       " -0.007557073142379522,\n",
       " -0.03180530294775963,\n",
       " 0.013284176588058472,\n",
       " -0.02772374078631401,\n",
       " 0.05630657449364662,\n",
       " 0.0030418841633945704,\n",
       " 0.0533248633146286,\n",
       " -0.057911232113838196,\n",
       " -0.011325819417834282,\n",
       " -0.03117201291024685,\n",
       " 0.02560867741703987,\n",
       " 0.03389058634638786,\n",
       " -0.0010284401942044497,\n",
       " 0.015864897519350052,\n",
       " 0.010595201514661312,\n",
       " -0.02703780122101307,\n",
       " -0.0009308380540460348,\n",
       " -0.048152241855859756,\n",
       " 0.028179243206977844,\n",
       " 0.010320614092051983,\n",
       " 0.06662961095571518,\n",
       " -0.01655818335711956,\n",
       " -0.004431369248777628,\n",
       " 0.03823425993323326,\n",
       " -0.023408224806189537,\n",
       " -0.03558175638318062,\n",
       " -0.05829067528247833,\n",
       " -0.011181497015058994,\n",
       " -0.017684543505311012,\n",
       " -0.016141284257173538,\n",
       " -0.0342453196644783,\n",
       " -0.025139551609754562,\n",
       " 0.03939668461680412,\n",
       " -0.023658234626054764,\n",
       " -0.007725016213953495,\n",
       " -0.00509891752153635,\n",
       " -0.035234373062849045,\n",
       " -0.014076859690248966,\n",
       " -0.22326026856899261,\n",
       " -0.03147135302424431,\n",
       " -0.0012906143674626946,\n",
       " -0.001720004016533494,\n",
       " -0.007846067659556866,\n",
       " -0.05802321061491966,\n",
       " 0.04617457091808319,\n",
       " 0.024552658200263977,\n",
       " 0.07320842146873474,\n",
       " 0.017268331721425056,\n",
       " 0.047612059861421585,\n",
       " 0.013473300263285637,\n",
       " -0.00551602803170681,\n",
       " -0.014357838779687881,\n",
       " -0.009674320928752422,\n",
       " 0.04878250136971474,\n",
       " 0.030538110062479973,\n",
       " -0.024993935599923134,\n",
       " 0.02148621715605259,\n",
       " 0.017639800906181335,\n",
       " 0.053138937801122665,\n",
       " 0.01348500419408083,\n",
       " -0.023225978016853333,\n",
       " -0.02140396274626255,\n",
       " 0.02607536129653454,\n",
       " 0.002029178664088249,\n",
       " 0.12753745913505554,\n",
       " 0.08316837251186371,\n",
       " 0.044089462608098984,\n",
       " -0.026703588664531708,\n",
       " 0.005521995481103659,\n",
       " -0.00929489079862833,\n",
       " 0.020074332132935524,\n",
       " -0.09684175252914429,\n",
       " -0.02470390684902668,\n",
       " 0.02508697099983692,\n",
       " 0.0020886347629129887,\n",
       " -0.044894032180309296,\n",
       " -0.07861136645078659,\n",
       " -0.0043763271532952785,\n",
       " -0.06590451300144196,\n",
       " 0.014689410105347633,\n",
       " -0.05764184892177582,\n",
       " -0.07152025401592255,\n",
       " -0.06232647970318794,\n",
       " 0.0034316526725888252,\n",
       " -0.046065498143434525,\n",
       " 0.045300863683223724,\n",
       " -0.026762275025248528,\n",
       " 0.034010905772447586,\n",
       " 0.045473795384168625,\n",
       " -0.028179263696074486,\n",
       " 0.005011825356632471,\n",
       " 0.00963081605732441,\n",
       " -0.030305609107017517,\n",
       " -0.036124806851148605,\n",
       " -0.01362694799900055,\n",
       " -0.03265373408794403,\n",
       " -0.04467753320932388,\n",
       " 0.010642164386808872,\n",
       " -0.02748633548617363,\n",
       " -0.02456512674689293,\n",
       " -0.024747759103775024,\n",
       " 0.05361957848072052,\n",
       " 0.020789967849850655,\n",
       " 0.019468484446406364,\n",
       " 0.05324121192097664,\n",
       " -0.014002446085214615,\n",
       " 0.021243266761302948,\n",
       " -0.04957323893904686,\n",
       " -0.008522573858499527,\n",
       " 0.007852843031287193,\n",
       " -0.05719393864274025,\n",
       " -0.02755063772201538,\n",
       " 0.005300902295857668,\n",
       " 0.04007291421294212,\n",
       " 0.019597917795181274,\n",
       " -0.045197341591119766,\n",
       " 0.0324358195066452,\n",
       " -0.012342402711510658,\n",
       " 0.034314434975385666,\n",
       " 0.02110210433602333,\n",
       " 0.03984643891453743,\n",
       " 0.03166380524635315,\n",
       " -0.033590227365493774,\n",
       " 0.03164786100387573,\n",
       " -0.0033045161981135607,\n",
       " 0.0046418230049312115,\n",
       " 0.037589333951473236,\n",
       " -0.059244584292173386,\n",
       " 0.007028361316770315,\n",
       " 0.003808695590123534,\n",
       " -0.025788886472582817,\n",
       " -0.021203329786658287,\n",
       " 0.022691231220960617,\n",
       " -0.0217729639261961,\n",
       " -0.27963775396347046,\n",
       " 0.007267427165061235,\n",
       " 0.021071992814540863,\n",
       " 0.045197442173957825,\n",
       " -0.020534474402666092,\n",
       " 0.024313710629940033,\n",
       " -0.0006136957672424614,\n",
       " -0.011857032775878906,\n",
       " -0.03296774998307228,\n",
       " 0.035843122750520706,\n",
       " 0.0312817245721817,\n",
       " 0.06373954564332962,\n",
       " 0.046547841280698776,\n",
       " -0.014470528811216354,\n",
       " 0.01586969941854477,\n",
       " 0.03397127985954285,\n",
       " 0.018059570342302322,\n",
       " 0.0022987432312220335,\n",
       " 0.01654987223446369,\n",
       " -0.02171488106250763,\n",
       " -0.034859977662563324,\n",
       " -0.0008649308583699167,\n",
       " 0.15126042068004608,\n",
       " -0.024536756798624992,\n",
       " 0.030671194195747375,\n",
       " -0.007318188901990652,\n",
       " -0.006135452538728714,\n",
       " 0.06415145844221115,\n",
       " 0.0160214826464653,\n",
       " -0.036364443600177765,\n",
       " 0.01989860087633133,\n",
       " -0.02117234282195568,\n",
       " 0.04829414188861847,\n",
       " -0.04478096961975098,\n",
       " 0.047633808106184006,\n",
       " 0.0007749291253276169,\n",
       " -0.005927960388362408,\n",
       " 0.06154267489910126,\n",
       " 0.02396841160953045,\n",
       " 0.013305011205375195,\n",
       " 0.022684475407004356,\n",
       " 0.014538074843585491,\n",
       " -0.052159037441015244,\n",
       " -0.03274967148900032,\n",
       " 0.08583346754312515,\n",
       " -0.0037248360458761454,\n",
       " 0.0013494138838723302,\n",
       " 0.04091988503932953,\n",
       " 0.011659682728350163,\n",
       " 0.05843620374798775,\n",
       " -0.02228615991771221,\n",
       " -0.011520684696733952,\n",
       " 0.004705687053501606,\n",
       " 0.047182597219944,\n",
       " -0.001917903427965939,\n",
       " 0.03300938010215759,\n",
       " -0.03505055233836174,\n",
       " -0.020736567676067352,\n",
       " -0.009222198277711868,\n",
       " 0.014618275687098503,\n",
       " 0.006456049624830484,\n",
       " 0.0010978562058880925,\n",
       " 0.010224007070064545,\n",
       " 0.08537216484546661,\n",
       " 0.03883952647447586]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
